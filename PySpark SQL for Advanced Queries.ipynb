{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4952a22-e2fa-4c68-9392-304e0d862db7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7f3bc4d48340>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"PySparkSQLAdvanced\").getOrCreate()\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "942de9a1-f78b-4308-9dc9-9a7aaae1befd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+---+------+------+\n| ID|Experience_Years|Age|Gender|Salary|\n+---+----------------+---+------+------+\n|  1|               5| 28|Female|250000|\n|  2|               1| 21|  Male| 50000|\n|  3|               3| 23|Female|170000|\n|  4|               2| 22|  Male| 25000|\n|  5|               1| 17|  Male| 10000|\n+---+----------------+---+------+------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"dbfs:/FileStore/shared_uploads/Employee_Salary_Dataset.csv\")\n",
    "\n",
    "# Show the first 5 rows\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bd50689-c8ab-4cfe-959c-1ab73f22a427",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"employees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9373d462-f36a-4459-ab33-24bc2dae0027",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+---+------+-------+\n| ID|Experience_Years|Age|Gender| Salary|\n+---+----------------+---+------+-------+\n|  1|               5| 28|Female| 250000|\n|  2|               1| 21|  Male|  50000|\n|  3|               3| 23|Female| 170000|\n|  4|               2| 22|  Male|  25000|\n|  5|               1| 17|  Male|  10000|\n|  6|              25| 62|  Male|5001000|\n|  7|              19| 54|Female| 800000|\n|  8|               2| 21|Female|   9000|\n|  9|              10| 36|Female|  61500|\n| 10|              15| 54|Female| 650000|\n| 11|               4| 26|Female| 250000|\n| 12|               6| 29|  Male|1400000|\n| 13|              14| 39|  Male|6000050|\n| 14|              11| 40|  Male| 220100|\n| 15|               2| 23|  Male|   7500|\n| 16|               4| 27|Female|  87000|\n| 17|              10| 34|Female| 930000|\n| 18|              15| 54|Female|7900000|\n| 19|               2| 21|  Male|  15000|\n| 20|              10| 36|  Male| 330000|\n+---+----------------+---+------+-------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\"SELECT * FROM employees WHERE salary > 5000\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1203f4ed-82ac-43b9-8914-890e8b9bc6b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n|Gender|        avg_salary|\n+------+------------------+\n|Female|2054916.6666666667|\n|  Male|2063626.4705882352|\n+------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\"\"\"\n",
    "    SELECT Gender, AVG(salary) AS avg_salary\n",
    "    FROM employees\n",
    "    GROUP BY Gender\n",
    "\"\"\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46167b64-d28d-49ea-bb95-4e7917d4dcef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+---+------+--------+-----------------+\n| ID|Experience_Years|Age|Gender|  Salary|cumulative_salary|\n+---+----------------+---+------+--------+-----------------+\n| 28|              27| 62|Female|10000000|            1.0E7|\n| 33|              20| 55|Female| 1540000|          1.154E7|\n|  3|               3| 23|Female|  170000|          1.171E7|\n| 26|               3| 22|Female|   20000|          1.173E7|\n|  1|               5| 28|Female|  250000|          1.223E7|\n| 11|               4| 26|Female|  250000|          1.223E7|\n| 29|              19| 54|Female| 5000000|          1.723E7|\n| 24|               1| 21|Female|    6000|         1.7236E7|\n| 30|               2| 21|Female|    6100|        1.72421E7|\n|  9|              10| 36|Female|   61500|        1.73036E7|\n| 10|              15| 54|Female|  650000|        1.79536E7|\n| 18|              15| 54|Female| 7900000|        2.58536E7|\n|  7|              19| 54|Female|  800000|        2.66536E7|\n| 16|               4| 27|Female|   87000|        2.67406E7|\n| 25|               4| 23|Female|    8900|        2.67495E7|\n|  8|               2| 21|Female|    9000|        2.67585E7|\n| 17|              10| 34|Female|  930000|        2.76885E7|\n| 34|              19| 53|Female| 9300000|        3.69885E7|\n|  5|               1| 17|  Male|   10000|          10000.0|\n| 12|               6| 29|  Male| 1400000|        1410000.0|\n+---+----------------+---+------+--------+-----------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import sum\n",
    "\n",
    "# Define a window specification\n",
    "window_spec = Window.partitionBy(\"gender\").orderBy(\"salary\")\n",
    "\n",
    "# Add a cumulative salary column\n",
    "df_with_cumulative = df.withColumn(\"cumulative_salary\", sum(\"salary\").over(window_spec))\n",
    "\n",
    "# Show the result\n",
    "df_with_cumulative.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c622dd3-5a8b-43fa-b363-75ca969c35dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n| Id|  salary|\n+---+--------+\n|  6| 5001000|\n| 13| 6000050|\n| 18| 7900000|\n| 21| 6570000|\n| 23| 6845000|\n| 28|10000000|\n| 29| 5000000|\n| 34| 9300000|\n| 35| 7600000|\n+---+--------+\n\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\"\"\"\n",
    "    SELECT Id, salary\n",
    "    FROM employees\n",
    "    WHERE salary > (SELECT AVG(salary) FROM employees)\n",
    "\"\"\")\n",
    "result.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "PySpark SQL for Advanced Queries",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
